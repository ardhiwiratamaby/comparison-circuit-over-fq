%Since comparison between numbers is a common operation required in many applications, its homomorphic evaluation has been the object of several works.
%Since inputs are encrypted, a comparison algorithm cannot terminate whenever the first difference between most significant bits is detected. 
%As a consequence, homomorphic comparison has a complexity corresponding to the worst-case complexity in the plain domain. 
%However, the practical efficiency of homomorphic comparison depends on an HE scheme.Since comparison is a common function required in many applications, its homomorphic evaluation has been the object of several works.
Comparison is a common function required in many applications; as a consequence, its homomorphic evaluation has been the object of several works.
Since inputs are encrypted, a comparison algorithm cannot terminate whenever it finds the first difference between most significant bits. 
As a result, homomorphic comparison has a complexity corresponding to the worst-case complexity in the plain domain. 
The practical efficiency of homomorphic comparison depends on the type of HE schemes considered.

For bit-wise HE schemes (FHEW, TFHE), Chillotti~et~al.~\cite{AC:CGGI17,JC:CGGI20} showed that one could compare two $n$-bit integers by evaluating a deterministic weighted automata made of $5n~\texttt{CMux}$ gates. 
Using the TFHE scheme, evaluating a \texttt{CMux} gate takes around $34$ microseconds on a commodity laptop, meaning that one can homomorphically compare two $n$-bit numbers in around $170n$ microseconds. 
Note that these estimations correspond to the fastest (leveled) version of TFHE which avoids bootstrapping. 
If one wants to use the bootstrapped version then the best method requires to evaluate $7n~\texttt{Mux}$ gates, where each gate takes around $13$ millisecond to be evaluated, which makes a total of $91n$ millisecond.

Schemes from the second category (BGV and BFV) can use \ac{SIMD} techniques to batch several plaintexts into a single ciphertext~\cite{SV14}. 
Therefore, a natural idea would be to pack the input bits into a single ciphertext. 
Cheon et al.~\cite{CKK15,CKK16} studied comparison functions in this context using the bivariate polynomial interpolation. 
Some of the algorithmic tools they have used -- e.g. computation of running sums and products -- are optimal~\todo{What do you mean by `optimal'?} in the homomorphic setting and have laid the ground for future works in this direction.

Some works have tried to exploit other features of these schemes by encoding integers modulo an odd prime $p$ instead of bits. 
In \cite{NGEG17}, Narumanchi et al. compare integer-wise comparison algorithms based on the univariate interpolation with bit-wise counterparts.
The SIMD packing was ignored in this study.
They concluded that bit-wise methods are more efficient because they have a smaller multiplicative depth.
In particular, $n$-bit numbers can be compared with a circuit of depth $\mathcal{O}(\log n)$ instead of $\mathcal{O}(n)$ in the case of integer-wise algorithms.
This comes from the fact that integer-wise comparison circuits require to evaluate a Lagrange interpolation polynomial of degree $p-1 \geq 2^n$.

In \cite{KLLW18}, Kim et al. noticed that SIMD packing techniques reduce the multiplicative complexity of homomorphic comparison circuits.
In addition, they took advantage of the nature of the finite field $\F_{p^d}$, which corresponds to the plaintext space of a SIMD slot.
Namely, any power $x^{p^i}$ can be evaluated with the homomorphic Frobenius automorphism $x \mapsto x^{p}$, which does not consume any homomorphic multiplicative depth level. 
This allowed to reduce the depth of the equality circuit $\EQ(x,y) = 1 - (x-y)^{p^{d}-1}$ from $\ceil{d\log_2(p)}$ to $\ceil{\log_2(d)} + \ceil{\log_2(p-1)}$.

Tan et al.~\cite{TLWRK20} proposed a method to perform digit-wise comparison using \ac{SIMD} and the bivariate polynomial interpolation.
Their idea consists in decomposing input integers into digits of size $p^r$ encoded into a subfield of $\F_{p^d}$, with $r | d$, in order to reduce the degree of the Lagrange interpolation polynomial of a comparison function. 
To compare input integers, one should extract digits, compare them and combine the results of digit comparison using the lexicographical order. 
Note that their evaluation of the lexicographical order intensively uses the efficient equality circuit of Kim et al.~\cite{KLLW18}. 
Overall, they have used their method to compare integers up to 64-bit while reporting, to the best of our knowledge, the current best timings for performing homomorphic comparison with BGV scheme. 

Finally, in \cite{PoPETS:SFR20}, Shaul et al. used the univariate approach to evaluate comparison functions in the context of top-$k$ selection with integer-wise circuits. 
However, they did not use the decomposition method of Tan et al.~\cite{TLWRK20}, thus obtaining relatively poor performance of comparison.

Note that all these works did not exploit the structure of comparison interpolation polynomials neither in the bivariate nor in the univariate case. 
Kaji et al.~\cite{JMC:KMNN19} described basic properties of the polynomial expressions of $\max$, $\argmax$ and other non-arithmetic functions over non-binary prime fields $\F_p$. 
However, their results do not allow to evaluate these functions very efficiently, as an example their homomorphic circuit to evaluate $\max$ has a quadratic complexity in $p$.

The situation for the CKKS scheme is quite different since its plaintext space natively supports complex/real numbers. 
Therefore, circuit optimizations related to data encoded into finite fields are not applicable for CKKS. 
Nonetheless, the approximated nature of computations in CKKS makes it suitable to use iterative methods from real analysis to compute close approximations of non-arithmetic functions. 
Bajard et al.~\cite{BMSZ20} used Newton iteration to evaluate the sign function, while independently Cheon et al.~\cite{AC:CKKLL19,EPRINT:CheKimKim19} generalized this approach and studied its efficiency in more details. 
Using the methods of~\cite{EPRINT:CheKimKim19}, one can compare 20-bit numbers with an amortized cost of $5.7$ milliseconds (see Table~\ref{table:other_he_schemes}), which is comparable, although slower, to TFHE. 
However, in order to obtain these timings one has to use quite large encryption parameters (ring dimension $2^{17}$ and ciphertext modulus up to $2200$ bits). 
Since the cost of homomorphic operations increases quasi-linearly with the ring dimension, while the number of slots only increases linearly, increasing the dimension would affect significantly the timings. 
Therefore, it would be interesting to know whether these methods can be used in practice to compare larger inputs -- e.g. 64-bit integers -- without degrading the performance. 

% \begin{itemize}
% \item \cite{CDSS15}: depth optimized sorting algorithm for HE. Reduce the depth from $\mathcal{O}(l\log^2(N))$ of Batcher network to $\mathcal{O}(\log(N) + \log(l))$ for sorting $N$ $l$-bits integers.

% \item \cite{EGNS15}: sorting algorithm for HE. Conclusion: average case in the encrypted domain corresponds to the worst-case in plain domain, better use sorting networks.

% \item \cite{CKK15,CKK16} (conference and journal extended version) bit wise comparison using SIMD. Algorithm to compute running products.

% \item \cite{KLLW18} equality circuit over non-binary fields. Use the Frobenius automorphism to reduce the depth. 
  
% \item \cite{NGEG17}: analysis of bit-wise and digit-wise comparison. Conclusion: bit-wise is more efficient because it has depth $\mathcal{O}(\log(l))$ instead of $\mathcal{O}(l)$ for digit-wise comparisons. Does not use the depth-free Frobenius automorphism\dots

% \item \cite{JS19}: bit-wise comparison using SIMD. Conclusion: more efficient than without SIMD. Less interesting than \cite{CKK15} and does not even cite it.

% \item \cite{AC:CKKLL19,EPRINT:CheKimKim19}: comparison and min/max functions with CKKS.

% \item \cite{AC:CGGI17}: TFHE-based min/max functions. It is faster than we thought. The fastest algorithm to compare two $n$-bit integers takes $170n$ microseconds, which is comparable to our timings.
 
% \item \cite{LKN19}: modified shell sort. Make shell sort more efficient for HE from $\mathcal{O}(n^2)$ to $\mathcal{O}(n^{3/2}\sqrt{\alpha+\log\log n})$ with failure probability of $2^{-\alpha}$. Complexity worst than for Batcher even-odd merge sort network.

% \item \cite{TLWRK20}: Digit-wise comparison using SIMD. Reduce complexity of digit-wise comparison from $\mathcal{O}(t^{d})$ to $\mathcal{O}(t^{r})$ for $r < d$ by decomposing each element in several digits. Compare numbers up to $64$ bits. Depth smaller than $\log(t-1) + \log(d) + 1$ (same algo than us, probably the work to compare with).

% \item \cite{AINA:NGEG17}: the univariate circuit is used in the context of sorting. There is no formal description of the circuit properties and complexity. Neither the decomposition method of~\cite{TLWRK20} or the lexicographic circuit is used.

% \item \cite{PoPETS:SFR20}: the univariate circuit is used in the context of top-$k$ selection. As above, there is no formal description of the circuit properties and complexity. Neither the decomposition method of~\cite{TLWRK20} or the lexicographic circuit is used. Their minimum function is based on the comparison table from~\cite{CDSS15}, but its multiplicative complexity is quadratic in the length of an input array. In our case, it is $O(n \log n)$.

% \item \cite{JMC:KMNN19}: this work studies polynomial expressions on $\max$, $\argmax$ and other non-arithmetic functions on finite fields. The homomorphic circuit of $\max$ derived from these expressions has a quadratic complexity in $p$. 

% \end{itemize}


  
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main_pets"
%%% End:
