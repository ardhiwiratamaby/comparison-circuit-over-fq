%As explained in Section \ref{sec:background}, comparing elements over $\mathbb{F}_{p^d}$ boils down to their comparison over $\mathbb{F}_p$. 
In this section, we study the structure of basic comparison circuits over $\mathbb{F}_p$ used in Section~\ref{sec:background} to compare integers, namely $\LT_{\S}$ and $\EQ_{\S}$ for some $\S \subseteq [0, p-1]$. 

%Let $\S$ be a subset of $[0,p-1]$ such that $\S$ can be embedded canonically embedded into $\F_p$.
For any choice of $\S$, the corresponding equality function over $\F_p$ is equal to
\begin{align*}
  \EQ_{\S}(x,y) = 1 - (x-y)^{p-1}.
\end{align*}
Unfortunately, $\LT_{\S}$ is not that simple and universal and we have to rely on Lagrange interpolation (Lemma~\ref{lem:interpolation}) to compute it. 
Yet, there are two different ways to evaluate it.
The first method (as done in \cite{TLWRK20}) uses $\S = [0,p-1]$ and directly interpolates $\LT_{\F_p}(x,y)$ as a bivariate polynomial over $\F_{p}$.
The second approach (as done in \cite{NGEG17} and \cite{PoPETS:SFR20}) has $\S = [0, (p-1)/2]$ and interpolates a univariate polynomial of $\LT_{\S}(z, 0)$ with $z = x - y$.
%In this case, $x,y$ must belong to the set $[0, (p-1)/2]$. 
%However, these works evaluated $\LT_{\F_p}$ without exploiting its structure. 
In this section, we show how to exploit the structure of these polynomials to speed-up their evaluation.

\subsection{Bivariate interpolation of $\LT_\S$.}

  Let $\S = [0,p-1]$.
  The less-than function can be interpolated using Lemma~\ref{lem:interpolation} and the following truth table.
  \begin{table}[h]
    \centering
    \begin{tabular}{c|ccccc}
        $<$ & 0 & 1 & 2 & $\cdots$ & $p-1$ \\
        \hline
        0 & 0 & 1 & 1 & $\cdots$ & 1 \\
        1 & 0 & 0 & 1 & $\cdots$ & 1 \\
        2 & 0 & 0 & 0 & $\cdots$ & 1 \\
        $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
        $p-1$ & 0 & 0 & 0 & $\cdots$ & 0 \\
    \end{tabular}
  \end{table}
    
  In particular, the interpolation polynomial of $\LT_\S$ over $\F_p$ is equal to
  \begin{align*}%\label{eq:less_than_function}
    P_{\LT_\S}(X,Y) &= \sum_{a = 0}^{p-2} \EQ_\S(X,a)\sum_{b = a+1}^{p-1} \EQ_\S(Y,b) \nonumber\\
    = \sum_{a = 0}^{p-2}& \left(1-\left(X - a\right)^{p-1}\right) \sum_{b = a+1}^{p-1} \left(1-\left(Y - b\right)^{p-1}\right).
  \end{align*}
  Surprisingly, the total degree of $P_{\LT_\S}(X,Y)$ is only $p$ and its coefficients can be described by the following theorem.
  \begin{theorem} \label{thm:less_than_total_degree}
    Let $p>2$ be a prime number and $\S = [0,p-1]$, then the interpolation polynomial of $\LT_\S$ over $\F_p$ has the following form
    \begin{align*}
      P_{\LT_\S}(X,Y) = Y^{p-1} - \frac{p-1}{2} (XY)^{\frac{p-1}{2}} + \sum_{\substack{i,j>0, \\ i \ne j, \\ i+j \le p}} a_{ij} X^i Y^j 
    \end{align*}
    where $a_{ij} = \sum_{a=0}^{p-2} \sum_{b=a+1}^{p-1} a^{p-1-i} b^{p-1-j} \in \F_p$.
    The total degree of $P_{\LT_\S}(X,Y)$ is $p$.
  \end{theorem}
  \begin{proof}
    See Appendix \ref{app:proof_thm_less_than_total_degree}.
  \end{proof}
  From the definition of $\LT_\S$, one can easily prove the following facts about $P_{\LT_\S}$:
  \begin{itemize}[label=--]
    \item $P_{\LT_\S} (X, 0) = 0$, thus $Y$ divides $P_{\LT_\S} (X, Y)$;
    \item $P_{\LT_\S} (X, X) = P_{\LT_\S} (Y,Y) = 0$, thus $(X - Y)$ divides $P_{\LT_\S} (X, Y)$;
    \item $P_{\LT_\S} (p-1, Y)=0$ thus $X + 1$ divides $P_{\LT_\S} (X, Y)$.
  \end{itemize}
  Hence, there exists a bivariate polynomial $f(X,Y)$ of total degree $p - 3$ over $\F_p$ such that:
  \begin{equation}
    \label{eq:decomposition-LT}
    P_{\LT_\S} (X, Y) = Y(X - Y)(X + 1)f(X, Y).
  \end{equation}
  The following theorem describes the structure of $f(X,Y)$.
  \begin{theorem}\label{thm:decomposition-f}
    Let $p$ be an odd prime and $\S = [0,p-1]$.
    Let $P_{\LT_\S} (X, Y)$ be the interpolation polynomial of $\LT_\S$ over $\F_p$ and $P_{\LT_\S} (X, Y) = Y(X - Y)(X + 1)f(X, Y)$.
    Then, for any $z \in \F_p$ we have
    \begin{equation}
      \label{eq:3}
       f(z,z) = f(z,0) = f(p-1,z).
    \end{equation}
    As a consequence, 
    %there exists a bivariate polynomials $f_1(X,Y)$ of total degree $p-5$ over $\F_p$ such that:
    %\begin{align}
    %  \label{eq:dec-f}
    %  f(X,Y) &= f(X,0) + Y(X-Y)f_1(X,Y) \nonumber \\
    %  &= f_0(X) + Y(X-Y)f_1(X,Y).
    %\end{align}   
    %This decomposition can be applied recursively to $f_1(X,Y)$, so that 
    there exists $(p-1)/2$ polynomials $f_i(X)$ over $\F_p$, $0\leq i \leq (p-3)/2$, such that:
    \begin{align}\label{eq:decomposition-f-final}
      f(X,Y) = \sum_{i=0}^{(p-3)/2} f_i(X)Z^i,
    \end{align}
    with $Z=Y(X-Y)$ and $\deg (f_{i}(X)) = p-3 - 2i$.

    % or equivalently a bivariate polynomials $f'_1$ of total degree $p-5$ over $\F_p$ such that:
    % \begin{equation}
    %   \label{eq:dec-f'}
    %   f(x,y) = f(p-1,y) + (x+1)(x-y)f'_1(x,y)
    % \end{equation}    
  \end{theorem}  

  Since our proof of Theorem~\ref{thm:decomposition-f} is quite long and with no real interest for the purpose of this work, we defer it to an extended version of this paper. 
  In our experiments, we used the decompositions~(\ref{eq:decomposition-f-final}) of $f(X,Y)$ only for small $p$ (between $3$ and $7$), which you can find in Appendix~\ref{app:decomposition-f}.\newline
  
%   In order to show Eq. (\ref{eq:3}) we will need the following lemma:

%   \begin{lemma}\label{lem:structure-f}
%     Let $p>3$ be an odd prime, $i\in[0,p-2]$ and $f$ be the polynomial defined in Eq. (\ref{eq:decomposition-LT}), then for any $z\in[0,p-1]$ we have:

%     $$ f(i,z) = f(p-1-z,p-1-i) = -\displaystyle\sum_{k=i+1}^{p-1}\frac{1-(z-k)^{p-1}}{(i+1)z(z-i)} \bmod p.$$
%   \end{lemma}

%   \begin{proof}
%     We know that for any $z\in[0,p-1]$ we have:
%     $$\LT_\S(i,z) = \left\{
%       \begin{array}{l}
%         0 ~\text{ if }~ 0\leq z\leq i \\
%         1 ~\text{ otherwise}~
%       \end{array}
%     \right.$$
%     Note that since $i<p-1$, $\LT_\S(i,\cdot)$ is not the zero function. It can be interpolated by the univariate polynomial:
%     $$P_{\LT_\S}(i,z) = \displaystyle\sum_{k=i+1}^{p-1}\left[1-(z-k)^{p-1}\right] \bmod p. $$
    
%     Similarly:
%     \begin{align*}
%       P_{\LT_\S}(x,p-1-i) &= \displaystyle\sum_{k=0}^{p-2}\left[1-(x-k)^{p-1}\right]\displaystyle\sum_{l=k+1}^{p-1}\left[1-(p-1-i-l)^{p-1}\right] \\
%                           &= \displaystyle\sum_{k=0}^{p-2-i}\left[1-(x-k)^{p-1}\right]  \bmod p
%     \end{align*}
%     So:
%     \begin{align*}
%       P_{\LT_\S}(p-1-z,p-1-i) &= \displaystyle\sum_{k=0}^{p-2-i}\left[1-(p-1-z-k)^{p-1}\right]  \bmod p \\
%                               &= \displaystyle\sum_{k=i+1}^{p-1}\left[1-(k-z)^{p-1}\right]  \bmod p \\
%                               &= \displaystyle\sum_{k=i+1}^{p-1}\left[1-(z-k)^{p-1}\right]  \bmod p \\
%                               &=  P_{\LT_\S}(i,z) \bmod p.
%     \end{align*}
%     Now let $A$ be the bivariate polynomial defined over $\F_p$ by:
%     $$A(x,y) = y(x-y)(x+1).$$
%     We have:
%     \begin{align*}
%       A(p-1-z,p-1-i) &= -(i+1)(-z+i)(-z) \bmod p \\
%                      &= -(i+1)z(z-i) \bmod p\\
%                      &= A(i,z) \bmod p.
%     \end{align*}
%     Again, note that since $i < p-1$, $A(i,z)\neq 0 \bmod p$.
    
%     Starting from Eq. (\ref{eq:decomposition-LT}) we can write:
%     \begin{align*}
%       P_i(z) =& A(i,z)f(i,z) = A(p-1-z,p-1-i)f(p-1-z,p-1-i) \bmod p \\
%       \Leftrightarrow & A(i,z)f(i,z) - A(p-1-z,p-1-i)f(p-1-z,p-1-i) = 0 \bmod p \\
%       \Leftrightarrow & A(i,z)(f(i,z) - f(p-1-z,p-1-i)) = 0 \bmod p
%     \end{align*}
%     Given that $A(i,z)\neq 0 \bmod p$ and that $\F_p[z]$ is an integral domain we obtain what we want:

%     $$ f(i,z) = f(p-1-z,p-1-i) \bmod p. $$

%     The last equality is obtained by dividing $P_{LT_\S}(i,z)$ with $A(i,z)\neq 0 \bmod p$.
%   \end{proof}
%   Now we can start the proof of Theorem \ref{thm:decomposition-f}.
%   \begin{proof}[Theorem \ref{thm:decomposition-f}]
%     Equation (\ref{eq:3}) says that the first column, the last line and the descending diagonal of the table of values of $f$ are equals (cf. Table \ref{tab:values-f}).
%     \begin{table}[h]
%       \centering
%       \begin{tabular}{m{1.5em}|m{1em}m{1em}m{1em}m{1em}m{1em}m{1em}c}
%         \backslashbox{$x$}{$y$} & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\
%         \hline
%         0 & \bf{0} & 6 & 5 & 3 & 3 & 5 & 6 \\
%         1 & \bf{4} & \bf{4} & 5 & 4 & 2 & 4 & 5 \\
%         2 & \bf{2} & 0 & \bf{2} & 3 & 2 & 3 & 2 \\
%         3 & \bf{2} & 0 & 0 & \bf{2} & 3 & 4 & 3 \\
%         4 & \bf{2} & 0 & 0 & 0 & \bf{2} & 5 & 5 \\
%         5 & \bf{4} & 0 & 0 & 0 & 0 & \bf{4} & 6 \\
%         6 & \bf{0} & \bf{4} & \bf{2} & \bf{2} & \bf{2} & \bf{4} & \bf{0} \\
%       \end{tabular}
%       \vspace{1em}\caption{Values $f(x,y)$ for $x,y\in\F_7$.}
%       \label{tab:values-f}
%     \end{table}
    
%     Lemma \ref{lem:structure-f} says that for any $0\leq i< p-1$ the $i$-th row (starting from $y=0$) and the $p-1-i$-th column (starting from $x=p-1$) of the table are equals. Another consequence of Lemma \ref{lem:structure-f} is that the values on any descending diagonal of the table form a palindrome (i.e. the values in the table are symmetric around the axis $x = p-1-y$). This is true in particular for the main descending diagonal $(x=y)$.

%     Now let us show that for any $0\leq i < p-1$ we have $f(i,0) = f(i,i)$. The case $i=0$ is trivial, for $i>0$ we know from Lemma \ref{lem:structure-f} that:
%     $$ f(i,z) = -\displaystyle\sum_{k=i+1}^{p-1}\frac{1-(z-k)^{p-1}}{(i+1)z(z-i)} \bmod p, $$
%     which can be rewritten modulo $p$ as:
%     \begin{align*}
%       f(i,z) & = -\frac{p-1-i - \displaystyle\sum_{k=i+1}^{p-1}(z-k)^{p-1}}{(i+1)z(z-i)} = -\frac{p-1-i - \displaystyle\sum_{k=i+1}^{p-1}\displaystyle\sum_{j=0}^{p-1}z^j k^{p-1-j}}{(i+1)z(z-i)} \\
%              & = -\frac{p-1-i - \displaystyle\sum_{j=0}^{p-1}\left(\displaystyle\sum_{k=i+1}^{p-1} k^{p-1-j}\right)z^j}{(i+1)z(z-i)}  = \frac{\displaystyle\sum_{j=1}^{p-1}\left(\displaystyle\sum_{k=i+1}^{p-1} k^{p-1-j}\right)z^{j-1}}{(i+1)(z-i)}.
%     \end{align*}
%     Similarly:
%     \begin{align*}
%       f(i,z) & = -\frac{p-1-i - \displaystyle\sum_{k=1}^{p-1-i}(z-i-k)^{p-1}}{(i+1)z(z-i)} = -\frac{p-1-i - \displaystyle\sum_{k=1}^{p-1-i}\displaystyle\sum_{j=0}^{p-1}(z-i)^j k^{p-1-j}}{(i+1)z(z-i)} \\
%              & = -\frac{p-1-i - \displaystyle\sum_{j=0}^{p-1}\left(\displaystyle\sum_{k=1}^{p-1-i} k^{p-1-j}\right)(z-i)^j}{(i+1)z(z-i)}  = \frac{\displaystyle\sum_{j=1}^{p-1}\left(\displaystyle\sum_{k=1}^{p-1-i} k^{p-1-j}\right)(z-i)^{j-1}}{(i+1)z}
%     \end{align*}

%     So for any $0 < i < p-1$, from the first expression we obtain:
%     $$f(i,0) = -\frac{\sum_{k=i+1}^{p-1} k^{p-2}}{i(i+1)},$$
%     from the second expression we get:
%     \begin{align*}
%       f(i,i) &= \frac{\sum_{k=1}^{p-1-i} k^{p-2}}{i(i+1)} = \frac{\sum_{k'=i+1}^{p-1} (p-k')^{p-2}}{i(i+1)} = \frac{\sum_{k'=i+1}^{p-1} (-k')^{p-2}}{i(i+1)} \bmod p \\
%       &= -\frac{\sum_{k'=i+1}^{p-1} (k')^{p-2}}{i(i+1)} = f(i,0).
%     \end{align*}

%     At this point we have shown that for $0\leq i<p-1$ we have $f(i,0) = f(i,i)$. 
%     This means that the first column and the descending diagonal are equals up to the last line. 
%     Since the values of the descending diagonal form a palindrome, the same applies to the values of the first column and thus of the last line. More precisely, for any $0\leq i < p-1$ we have:
%     $$f(i,0) = f(i,i) = f(p-1-i, p-1-i) = f(p-1-i, 0) = f(p-1, i)$$

%     At this point the last thing we have to prove to get Eq. (\ref{eq:3}) is that $f(0,0) = f(p-1,0) = f(p-1,p-1) \bmod p$. Lemma \ref{lem:structure-f} already gives us $f(0,0) = f(p-1,p-1)$, so we just have to prove the last one.

%     We have:
%     $$ P_{\LT_\S}(0,z)  = -\sum_{j=1}^{p-1}\left(\sum_{k=1}^{p-1}k^{p-1-j}\right)z^j  = z^{p-1} \bmod p \text{ (cf. Lemma \ref{lem:sum_poly}).} $$

%     Moreover, let $A(x,y) = y(x-y)(x+1)$, we have $A(0,z) = -z^2$. So from Eq.~(\ref{eq:decomposition-LT}) we obtain $f(0,z) = -z^{p-3}$ and so $f(0,0) = f(p-1,p-1) = -1 \bmod p$ if $p = 3$ and $0$ otherwise.

%     To conclude we have to show that $f(p-1,0) = -1 \bmod p$ if $p=3$ and $0$ otherwise. 
%     Since both $A$ and $\LT_\S$ vanish on the first column of the table ($y=0$) and the last line ($x=p-1$) we cannot use their values on these lines to derive the value of $f(p-1,0)$. So this time we will estimate $\LT_\S$ and $A$ on the ascending diagonal. Since $A(p-1-z,z) = z^2(1+2z) \bmod p$ if we want to prove that $f(p-1,0) = 0 \bmod p$ (resp. $1$ if $p=3$) we have to show that the coefficients of degree $0$, $1$ and $2$ of $P_{\LT_\S}(p-1-z,z)$ are equals to $0$, (resp $0, 1$ are equals to $0$ and the coefficient of degree $2$ is equal to $-1$).

%     By definition, $\LT_\S(p-1,0) = P_{LT_\S}(p-1,0) = 0 \bmod p$, so the coefficient of degree $0$ is equal to $0$. Now let us have a look at the formal derivative of $P_{\LT_\S}(p-1-z,z)$. We have: 
%     $$ P_{LT_\S}(p-1-z,z) = \sum_{k=0}^{p-2}\underbrace{[1-(1+z+k)^{p-1}]}_{=g_k(z)}\underbrace{\sum_{l=k+1}^{p-1}[1-(z-l)^{p-1}]}_{=h_k(z)} \bmod p $$
 
%   For $0\leq k \leq p-2$, we have $g_k(0) = 1-(1+k)^{p-1} = 0 \bmod p$, and also $h_k(0) = \sum_{l=k+1}^{p-1}[1-l^{p-1}] = 0 \bmod p$ since $0<l\leq p-1$. 

% Therefore $P'_{LT_\S}(p-1,0) = \sum_{k=0}^{p-2}\left(g_k'(0)h_k(0) + g_k(0)h'_k(0) \right) = 0 \bmod p$ therefore the coefficient of degree $1$ is also equal to $0$. 

% Now let us consider the formal derivative at the second order of $P_{\LT_\S}(p-1-z)$:
% $$P''_{\LT_\S}(p-1-z,z) = \sum_{k=0}^{p-2}\left(g_k''(z)h_k(z) + 2g_k'(z)h'_k(z) + g_k(z)h''_k(z) \right).$$
% Thus in $z=0$ we obtain: 
% \begin{align*}
%   P''_{\LT_\S}(p-1,0) & = 2\sum_{k=0}^{p-2}g_k'(0)h'_k(0) = -2\sum_{k=0}^{p-2}(1+k)^{p-2}\sum_{l=k+1}^{p-1}l^{p-2} \\
%                       &= -2\left(\sum_{k=1}^{(p-1)/2}k^{p-2}\sum_{l=k}^{p-1}l^{p-2} + \sum_{k=(p+1)/2}^{p-1}k^{p-2}\sum_{l=k}^{p-1}l^{p-2}\right) \\
%                       & = -2\left(\sum_{k=1}^{(p-1)/2}k^{p-2}\sum_{l=k}^{p-1}l^{p-2} + \sum_{k=1}^{(p-1)/2}(-k)^{p-2}\sum_{l=p-k}^{p-1}l^{p-2}\right) \\
%                       & = -2\sum_{k=1}^{(p-1)/2}k^{p-2}\left(\sum_{l=k}^{p-1}l^{p-2} -  \sum_{l=p-k}^{p-1}l^{p-2}\right) \\
%                       & = -2\sum_{k=1}^{(p-1)/2}k^{p-2}\sum_{l=k}^{p-1-k}l^{p-2} = -2\sum_{k=1}^{(p-1)/2}k^{2p-4} \\
%                       & = -2\sum_{k=1}^{(p-1)/2}k^{p-3} = -\sum_{k=1}^{(p-1)/2}k^{p-3} - \sum_{k=1}^{(p-1)/2}(-k)^{p-3} \\
%                       & = -\sum_{k=1}^{p-1}k^{p-3}  \bmod p\\
%                       & = 1 ~\text{ if } p = 3 ~\text{ and }~ 0 ~\text{ otherwise.}
% \end{align*}
% The coefficient of degree 2 is equal to $P''_{\LT_\S}(p-1,0)/2 = -1 \bmod 3$.
% Thus overall $f(p-1,0) = f(p-1,p-1) = f(0,0)$ and we have proved Eq. (\ref{eq:3}). The rest of the theorem is straightforward:
% \begin{itemize}
% \item $y$ and $(x-y)$ divide $f(x,y)-f(x,0) = f(x,y)-f(x,x) \bmod p$ which implies (\ref{eq:dec-f}). 
% \item $x+1$ and $(x-y)$ divide $f(x,y)-f(p-1,y) = f(x,y)-f(y,y) \bmod p$ which implies (\ref{eq:dec-f'}).
% \end{itemize}
% Note that when $p=3$ $f(x,y) = 1 \bmod p.$
% \end{proof}

\textbf{Complexity analysis.}
In \cite{TLWRK20}, the authors proposed to evaluate $P_{\LT_S}(X,Y)$ by evaluating each monomials separately before summing them up. 
Given $x,y \in \F_p$, they precompute the powers of $x$ and $y$ up to $p-1$ for a total of $2p-4$ non-scalar multiplications. 
Then, another $p-1$ non-scalar multiplications are needed to evaluate each monomial $((\sum_i c_i X^i)Y^j)_{j}$ where $c_i$'s are scalars in $\F_p$, before summing them together to get the final result. 
Overall their evaluation of $P_{\LT_\S}(X,Y)$ requires $3p-5$ non-scalar multiplications.

Following this idea and using the decomposition of $f(X,Y)$ given in Eq. (\ref{eq:decomposition-f-final}) one needs:
\begin{itemize}
\item $2$ multiplications to compute $(X+1)Z$ if $p\geq 3$ or $1$ multiplication when $p=2$;
\end{itemize}
and then for $p\geq 5$:
\begin{itemize}
\item $p-4$ multiplications to compute the $X^i$'s for $2\leq i \leq p-3$ required to compute the terms $f_i(X)$;
\item $(p-5)/2$ multiplications to compute the $Z^i$ for $2\leq i \leq (p-3)/2$;
\item $(p-5)/2$ multiplications to compute the products $f_i(X)\cdot Z^i$;
\item $1$ final multiplication $(X+1)Z\cdot f(X,Y)$.
\end{itemize}
Overall, at most $2p-6$ non-scalar multiplications are needed to homomorphically evaluate $P_{\LT_\S}(X,Y)$ for \mbox{$p \geq 5$}. 
This number can be slightly reduced by optimizing the way of computing $f_i$'s. 
For instance, it can be done with only $6$ multiplications for $p=7$, respectively (see Appendix \ref{app:decomposition-f}), which is smaller than $2p-6=8$.

Overall, for $p\geq 5$, our method saves $p+1$ multiplications over the method of Tan et al.~\cite{TLWRK20}. 
However, the complexity of the bivariate circuit remains linear in $p$ which is unpractical for performing homomorphic comparisons using large digits (i.e. a large $p$).
  
\subsection{Univariate interpolation of $\LT_\S$}
Unlike bivariate polynomials, it is possible to evaluate univariate polynomials of degree $p-1$ in $\mathcal{O}(\sqrt{p})$ non-scalar multiplications using the Paterson-Stockmeyer algorithm~\cite{SIAM:PS73}. 
To evaluate $\LT_S$ as a univariate polynomial, we compute the difference $x-y$ of the two input values and check its sign.
To compute the sign function using finite field arithmetic, we need to split finite field elements into two classes:  negative ($\F_p^-$) and non-negative ($\F_p^+$).
In addition, for any $x, y \in \S$ the following property should hold:
\begin{align*}
  x - y \in 
  \begin{cases}
    \F_p^+ \text{ if } \LT_\S(x,y) = 0, \\
    \F_p^- \text{ if } \LT_\S(x,y) = 1.
  \end{cases}
\end{align*}   
It is easy to see that these constraints are satisfied by $\S = [0, (p-1)/2]$.
Let us split $\F_p$ into $\F_p^+ = [0, (p-1)/2]$ and $\F_p^- = [-(p-1)/2, -1]$.
Notice that for any $x, y \in \S$, their difference $x - y$ belongs to $\F_p^-$ if and only if $x < y$.

Let $\chi_{\F_p^-}(z)$ be a function that outputs $1$ if $z$ is negative and $0$ otherwise.
According to Lemma~\ref{lem:interpolation}, $\chi_{\F_p^-}(z)$ is equal to
\begin{align*}
  \chi_{\F_p^-}(z) = \sum_{a=-\frac{p-1}{2}}^{-1} 1 - (z - a)^{p-1}.
\end{align*}
  Combining the above facts, the $\LT_\S$ function can be interpolated by the following polynomial over $\F_p$
  \begin{align*}
    Q_{\LT_\S}(X,Y) = \sum_{a=-\frac{p-1}{2}}^{-1} 1 - (X - Y - a)^{p-1}\,.
  \end{align*}
  The following theorem describes all the coefficients of this interpolation polynomial.
  \begin{theorem}\label{th:univariate}
    For an odd prime $p$ and $\S = [0, (p-1)/2]$, the $\LT_\S$ function can be interpolated by the following polynomial over $\F_p$
    \begin{align}\label{eq:univariate_circuit}
      Q_{\LT_\S}(X,Y) = \frac{p+1}{2} (X-Y)^{p-1} + \sum_{i=1, \text{odd}}^{p-2} c_i (X-Y)^i.
    \end{align}
    where $c_i = \sum_{a=1}^{\frac{p-1}{2}} a^{p-1-i}$.
  \end{theorem}
  \begin{proof}
    See Appendix \ref{app:proof-lem-univariate}
  \end{proof}
  \begin{remark}\label{rem:sign_function}
    The polynomial $Q_{\LT_\S}(X,Y)$ yields the interpolation polynomial of the sign function $\sign_{\S'}$ defined on $\S' = [-(p-1)/2, (p-1)/2]$ as $\sign_{\S'}(x) = 1$ if $x < 0$ and $\sign_{\S'}(x) = 1$ if $x \ge 0$.
    In particular, we have 
    \begin{align}\label{eq:sign_interpolation}
      Q_{\sign_{\S'}}(X) = Q_{\LT_\S}(X,0)\,.
    \end{align} 
  \end{remark}
  \textbf{Complexity analysis.} The above theorem implies that the less-than function can be expressed by a univariate polynomial of degree $p-1$.
  In general, such polynomials are evaluated in $p-1$ multiplications according to Horner's method.
  
  To reduce the number of non-scalar multiplications, we can resort to the Paterson-Stockmeyer algorithm~\cite{SIAM:PS73} that requires $\sqrt{2(p-1)} + \log_2 (p-1) + \mathcal{O}(1)$ such multiplications.
  However, we can improve this complexity by exploiting the fact that the polynomial in~(\ref{eq:univariate_circuit}) has only one coefficient with an even index, the leading one.
  Thus, if $Z=X-Y$, we can rewrite~(\ref{eq:univariate_circuit}) as follows
  \begin{align*}
    \alpha_{p-1} Z^{p-1} + Z \sum_{i=0, \text{even}}^{p-3} \alpha_{i+1} Z^i =  \alpha_{p-1} Z^{p-1} + Z g(Z^2)
  \end{align*}
  where $\alpha_i = \sum_{a=1}^{\frac{p-1}{2}} a^{p-1-i}$ and $g(X)$ is a polynomial of degree $(p-3)/2$.
  To evaluate $g(X)$, the Paterson-Stockmeyer algorithm requires $\sqrt{p-3} + \log_2 \left(\frac{p-3}{2}\right) + \mathcal{O}(1)$ non-scalar multiplications.
  Furthermore, the preprocessing phase of this algorithm computes the powers $Z^2, Z^4, \dots, Z^{2k}$ and $Z^{4k}, Z^{8k}, \dots, Z^{2^r k}$ with $2k(2^r-1) = p-3$.
  We can use these powers to compute the leading term in $r$ non-scalar multiplications, namely
  \begin{align*}
    Z^2 Z^{2k} Z^{4k} \cdots Z^{2^r k} = Z^{2 + 2k(2^r-1)} = Z^{2 + p - 3} = Z^{p-1}.
  \end{align*}
  Since the optimal $k$ is about $\sqrt{(p-3)/2}$, we obtain that $r$ must be about $\log_2 \sqrt{p-3}$.
  Hence, the total non-scalar complexity of evaluating~(\ref{eq:univariate_circuit}) is equal to
  \begin{align*}
    \sqrt{p-3} + \frac{3 \log_2 \left(p-3\right)}{2} + \mathcal{O}(1).
  \end{align*}
  
  \begin{remark}
    A careful reader can notice that the leading term of~(\ref{eq:univariate_circuit}) is equal to $(X-Y)^{p-1}$, which is the heaviest part of the equality circuit $\EQ_\S(X,Y)$.
    Thus, we can get $\EQ_\S(X,Y)$ almost for free (at the cost of one homomorphic subtraction) after evaluating $\LT_\S(X,Y)$, which saves $\mathcal{O}(\log (p-1))$ non-scalar multiplications.

    This feature of the univariate circuit allows to compute all the equality operations while comparing large integers using the less-than function $\LT$ from~(\ref{eq:general_lex_order}).
    This saves $\mathcal{O}((d'-1)(k-1) \log (p-1))$ homomorphic multiplications, thus leading to a better running time than for the bivariate circuit.

    The downside of the univariate circuit is that at most half of the plaintext space is used to encode input integers in comparison to the bivariate method.
  \end{remark}

\subsection{Min/max function}

  Given the less-than function $\LT$ defined on some set, one can compute the minimum of two elements $x, y$ of this set in the following generic way
  \begin{align}\label{eq:generic_minimum}
    \min(x,y) &= x \cdot \LT(x,y) + y \cdot (1 - \LT(x,y)) \nonumber\\
    &= y + (x-y) \cdot \LT(x,y)\,.
  \end{align}
  Notice that the input difference $x - y$ naturally emerges in this expression, thus hinting that the univariate circuit from~(\ref{eq:univariate_circuit}) might be useful here.
  Indeed, by replacing $X - Y$ with a variable $Z$ we obtain the univariate polynomial representation of the minimum function on the set $\S=[0,(p-1)/2]$ 
  \begin{align*}
    Q_{\min_\S}(X,Y) &= Y + Z \cdot Q_{\LT_S}(X,Y) \\
    & = Y + \frac{p+1}{2} Z + \sum_{i=1}^{\frac{p-1}{2}} Z^{2i} \sum_{a=1}^{\frac{p-1}{2}} a^{p-2i} \\
    & = \frac{p+1}{2} (X+Y) + \sum_{i=1}^{\frac{p-1}{2}} Z^{2i} \sum_{a=1}^{\frac{p-1}{2}} a^{p-2i} \\
    & = \frac{p+1}{2} (X+Y) + g(Z^2)\,,
  \end{align*}
  where $g(X)$ is a polynomial of degree $(p-1)/2$. 
  As a result, $\min_S(x,y)$ can be computed with $\mathcal{O}(\sqrt{p-1})$ non-scalar multiplications via the Paterson-Stockmeyer algorithm.

  Following the above reasoning, the maximum function can be computed with the following polynomial
  \begin{align*}
    Q_{\max_\S}(X,Y) &= \frac{p+1}{2} (X+Y) - \sum_{i=1}^{\frac{p-1}{2}} Z^{2i} \sum_{a=1}^{\frac{p-1}{2}} a^{p-2i}.
  \end{align*}
  \begin{remark}
    Maximum and minimum functions are basic building blocks in the design of neural networks.
    For example, one of the most popular activation functions in neural networks is the rectifier, or ReLU, which is equal to $\max(x,0)$.
    By analogy with~(\ref{eq:generic_minimum}), we have $\max(x,0) = x \cdot (1 - \sign_{\S'}(x))$ where $\S' = [-(p-1)/2,(p-1)/2]$ (see Remark~\ref{rem:sign_function}).
    Thus, Eq.~(\ref{eq:sign_interpolation}) yields the following interpolation polynomial of the ReLU function on $\S'$
    %The above polynomial of $\max_\S$ yields the following simple polynomial for the ReLU function defined on $\S=[0,(p-1)/2]$
    \begin{align*}
      Q_{\ReLU_{\S'}}(X) &= X \cdot (1 - Q_{\sign_{\S'}}(X))\\
      &= \frac{p+1}{2} X - \sum_{i=1}^{\frac{p-1}{2}} X^{2i} \sum_{a=1}^{\frac{p-1}{2}} a^{p-2i}.
    \end{align*}
  \end{remark}

% \subsection{Lexicographic order}\label{subsec:lexicographic_order}
%   Let $\vx=(x_0,x_1,\ldots,x_{\ell-1})$ and $\vy=(y_0,y_1,\ldots,y_{\ell-1}) \in \F_\fieldcard^\ell$ for the lexicographical order $<$ defined by the choice of $\S$:
%   \begin{align*}
%     \vx < \vy \Leftrightarrow \exists i\in[0,\ell-1] \text{ such that } x_i < y_i \text{ and } \forall j > i ~~ x_j = y_j\,.
%   \end{align*}
%   This order induces a function $\LT_{\F_\fieldcard}(\vx, \vy)$ that returns $1$ if $\vx < \vy$ and $0$ otherwise. 
%   As done in~\cite{TLWRK20}, we can employ $\EQ_{\F_\fieldcard}$ and $\LT_{\F_\fieldcard}$ to compute $\LT_{\F_\fieldcard}(\vx, \vy)$ as follows
%   \begin{align*}
%     \LT_{\F_\fieldcard}(\vx, \vy) = \sum_{i=0}^{\ell-2} \LT_{\F_\fieldcard}(x_{i}, y_{i}) \prod_{j=i+1}^{\ell-1} \EQ_{\F_\fieldcard}(x_{j}, y_{j}) + \LT_{\F_\fieldcard}(x_{\ell-1}, y_{\ell-1}).
%   \end{align*}
%   Notice that the multiplicative depth of this function solely depends on the products of the equality functions.
%   In fact, these products compare subvectors $\vx_i = (x_i, x_{i+1},\dots,x_{\ell-1})$ and $\vy_i = (y_i, y_{i+1},\dots,y_{\ell-1})$ for $i \in [1,\ell-1]$.
%   Thus, we can rewrite $\LT_{\F_\fieldcard}$ as
%   \begin{align}\label{eq:general_lex_order}
%     \LT_{\F_\fieldcard}(\vx, \vy) = \sum_{i=0}^{\ell-2} \LT_{\F_\fieldcard}(x_{i}, y_{i}) \EQ_{\F_\fieldcard}(\vx_{i+1}, \vy_{i+1}) + \LT_{\F_\fieldcard}(x_{\ell-1}, y_{\ell-1})
%   \end{align}
%   with the equality function $\EQ_{\F_\fieldcard}(\vx_{i+1}, \vy_{i+1})$ that returns $1$ if $\vx_{i+1} = \vy_{i+1}$ and $0$ otherwise.
%   As shown in~\todo{cite our work}, this function can be realized by a constant-depth circuit in the following way.
%   \begin{align}\label{eq:rand_eq_circuit}
%     \EQ_{\F_\fieldcard, e}(\vx_{i+1},\vy_{i+1}) = 1 - \princhar_{\fieldcard^e}\left(\sum_{j=i+1}^{\ell-1} r_j (x_j - y_j)\right)
%   \end{align}
%   where $r_j$ are uniformly random elements from $\F_{\fieldcard^e}$.
%   This circuit is false-biased with error probability $\fieldcard^{-e}$.
%   We can compute all $\EQ_{\F_\fieldcard, e}(\vx_{i+1},\vy_{i+1})$ using the same number of multiplications as for the single equality using Algorithm~\ref{alg:vector_equalities_circuit}.\todo{What is the complexity?}
%   \begin{algorithm}[t]
%     \KwIn{
%     $\ct_\vx$ -- a ciphertext encrypting $\vx \in \F^\ell_\fieldcard$,
%     $\ct_\vy$ -- a ciphertext encrypting $\vy \in \F^\ell_\fieldcard$.
%     }
%     \KwOut{$\ct$ -- a ciphertext containing the output of $\EQ_{\F_\fieldcard, e}(\vx_{i+1},\vy_{i+1})$ in the $i$th SIMD slot}
%     $\ct_1 \leftarrow \Shift(\ct_\vx, 1)$ // removes the value $x_0$ and shifts $\vx$ to the left\\
%     $\ct_2 \leftarrow \Shift(\ct_\vy, 1)$ // removes the value $y_0$ and shifts $\vy$ to the left\\
%     $\ct \leftarrow \Sub(\ct_1, \ct_2)$ // $(x_i - y_i), i \in [1,\ell-1]$\\
%     $r_0,r_1,\dots,r_{\ell-1} \leftarrow \udist(\F_{\fieldcard^e})$ //\todo{define uniform distribution}\\ 
%     $\pt_r \leftarrow \pt(r_0,r_1,\dots,r_{\ell-1})$\\
%     $\ct \leftarrow \ct \cdot \pt_r$ // $r_i(x_i - y_i), i \in [1,\ell-1]$\\
%     $k \leftarrow 1$// $\sum_{j=i}^{\ell-1} r_i(x_i - y_i), i \in [1,\ell-1]$\\
%     \While{$k < \ell-1$}{
%       $\ct_{tmp} \leftarrow \Shift(\ct, k)$\\
%       $\ct \leftarrow \ct + \ct_{tmp}$\\
%       $k \leftarrow 2k$\\
%     }
%     $\ct \leftarrow \Power(\ct, \fieldcard^e-1)$ //$\princhar_{\fieldcard^e}\left(\sum_{j=i}^{\ell-1} r_i(x_i - y_i)\right), i \in [1,\ell-1]$ \\
%     $\ct \leftarrow 1 - \ct$\\
%     \textbf{Return} $\ct$.
%     \caption{Homomorphic circuit computing $\EQ_{\F_\fieldcard, e}(\vx_{i+1},\vy_{i+1})$ in parallel.}\label{alg:vector_equalities_circuit}
%   \end{algorithm}
  
%   Let us go back to the lexicographic order in equation~(\ref{eq:general_lex_order}).
%   Assume that we have a ciphertext $\ct_{\LT}$ containing $\LT_{\F_\fieldcard}(x_i, y_i)$ in the $i$th slot (\todo{elaborate on that}) and the output $\ct_{\EQ}$ of Algorithm~\ref{alg:vector_equalities_circuit}.
%   We set the $\ell-1$ slot of $\ct_{\EQ}$ to $1$ and multiply it by $\ct_{\LT}$.
%   The resulting ciphertext contains all the products $\LT_{\F_\fieldcard}(x_{i}, y_{i}) \EQ_{\F_\fieldcard}(\vx_{i+1}, \vy_{i+1})$ for any $i \in [0,\ell-2]$ and $\LT_{\F_\fieldcard}(x_{\ell-1}, y_{\ell-1})$, which can be summed in the same way as in the while circuit of Algorithm~\ref{alg:vector_equalities_circuit}.
%   As a result, we obtain a ciphertext with the output of $\LT_{\F_\fieldcard}(\vx, \vy)$ in the first SIMD slot.

%   \subsubsection{Comparing large integers.}
%   Since any integer $z$ can be represented in base $\fieldcard$ as $z = \sum_{i=0}^{\ell-1} z_i q^i$, we can encode $z$ into SIMD slots as a vector $(z_0,z_1,\dots,z_{\ell-1}) \in \F_{\fieldcard}^\ell$.
%   As shown above, we can compare such vectors using the lexicographic order function in~(\ref{eq:general_lex_order}) and thus compare integers larger than $\fieldcard$.

%   \todo{Incorporate the following into the complexity analysis.} 
%   We can obtain ciphertexts encrypting $(x,x,\ldots, x)$ and $(y,y,\ldots, y)$ with $2\log_2(q-1)\texttt{Rot}$ and $2\log_2(q-1)\texttt{Add}$. 

%   From there we can obtain encryptions of $(x,x-1,\ldots, x-q-2)$ and $(y-1,y-2,\ldots, y-q-1)$ with $2\texttt{Add}$. We can apply $f$ to these vectors in parallel with a depth of $\log (p-1) + \log d$ for a cost of $2(\log (p-1) + wt(p-1) + d - 2) \texttt{Mult}$. This can be minimized by choosing $p = 2^d + 1$ for some $d$.

%   With $2$ more $\texttt{Sub}$ we obtain encryptions of $(1-f(x), 1-f(x-1), \ldots, 1-f(x-q-2))$ and $(1-f(y-1), 1-f(y-2), \ldots, 1-f(y-q-1))$. From there we can get an encryption of the different partial sums in $\log_2(q-1)\texttt{Rot}$, $\log_2(q-1)\texttt{Select}$ and $\log_2(q-1)\texttt{Add}$. The algorithm works as follow:

%   \begin{center}
%     \begin{tikzpicture}[scale=0.8]
%       \newcommand\y{-4};
      
%       \draw (0,2) -- (16,2);
%       \draw (0,0) -- (16,0);    
%       \foreach \x in {0,...,8}{
%         \draw (2*\x,0) -- (2*\x,2);
%       }
%       \foreach \x in {0,...,7}{
%         \node at (2*\x+1,1) {$x_\x$};
%       }

%       \draw (0,2+\y) -- (16,2+\y);
%       \draw (0,\y) -- (16,\y);    
%       \foreach \x in {0,...,8}{
%         \draw (2*\x,0+\y) -- (2*\x,2+\y);
%       }

%       \node at (1,1+\y) {$x_0 + x_1$};
%       \node at (3,1+\y) {$x_1 + x_2$};
%       \node at (5,1+\y) {$x_2 + x_3$};
%       \node at (7,1+\y) {$x_3 + x_4$};
%       \node at (9,1+\y) {$x_4 + x_5$};
%       \node at (11,1+\y) {$x_5 + x_6$};
%       \node at (13,1+\y) {$x_6 + x_7$};
%       \node at (15,1+\y) {$x_7$};

%       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      
%       \draw (0,2+2*\y) -- (16,2+2*\y);
%       \draw (0,0+2*\y) -- (16,0+2*\y);    
%       \foreach \x in {0,...,8}{
%         \draw (2*\x,0+2*\y) -- (2*\x,2+2*\y);
%       }

%       \node at (1,1+2*\y) {$\begin{array}{c}
%           x_0 + x_1  \\
%           + x_2 + x_3
%         \end{array}$};
%       \node at (3,1+2*\y) {$\begin{array}{c}
%           x_1 + x_2  \\
%           + x_3 + x_4
%         \end{array}$};
%       \node at (5,1+2*\y) {$\begin{array}{c}
%           x_2 + x_3  \\
%           + x_4 + x_5
%         \end{array}$};
%       \node at (7,1+2*\y) {$\begin{array}{c}
%           x_3 + x_4  \\
%           + x_5 + x_6
%         \end{array}$};
%       \node at (9,1+2*\y) {$\begin{array}{c}
%           x_4 + x_5  \\
%           +x_6 + x_7
%         \end{array}$};
%       \node at (11,1+2*\y) {$\begin{array}{c}
%           x_5 + x_6  \\
%           + x_7
%         \end{array}$};
%       \node at (13,1+2*\y) {$x_6 + x_7$};
%       \node at (15,1+2*\y) {$x_7$};

%       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      
%       \draw (0,2+3*\y) -- (16,2+3*\y);
%       \draw (0,0+3*\y) -- (16,0+3*\y);    
%       \foreach \x in {0,...,8}{
%         \draw (2*\x,0+3*\y) -- (2*\x,2+3*\y);
%       }

%       \node at (1,1+3*\y) {$\begin{array}{c}
%           x_0 + x_1  \\
%                               + x_2 + x_3 \\
%                               + x_4 + x_5 \\
%                               + x_6 + x_7
%         \end{array}$};
%       \node at (3,1+3*\y) {$\begin{array}{c}
%           x_1 + x_2  \\
%                               + x_3 + x_4 \\
%                               + x_5 + x_6 \\
%                               + x_7 \\
%         \end{array}$};
%       \node at (5,1+3*\y) {$\begin{array}{c}
%           x_2 + x_3  \\
%                               + x_4 + x_5 \\
%                               + x_6 + x_7
%         \end{array}$};
%       \node at (7,1+3*\y) {$\begin{array}{c}
%           x_3 + x_4  \\
%                               + x_5 + x_6 \\
%                               +x_7
%         \end{array}$};
%       \node at (9,1+3*\y) {$\begin{array}{c}
%           x_4 + x_5  \\
%           +x_6 + x_7
%         \end{array}$};
%       \node at (11,1+3*\y) {$\begin{array}{c}
%           x_5 + x_6  \\
%           + x_7
%         \end{array}$};
%       \node at (13,1+3*\y) {$x_6 + x_7$};
%       \node at (15,1+3*\y) {$x_7$};

%       \foreach \x in {2,...,8}
%       \draw[->,thick = 2pt] (2*\x-0.1-1,2) to[bend right] (2*\x-3+0.1,2);

%       \foreach \x in {3,...,8}
%       \draw[->,thick = 2pt] (2*\x-0.1-1,2+\y) to[bend right] (2*\x-5+0.1,2+\y);

%       \foreach \x in {5,...,8}
%       \draw[->,thick = 2pt] (2*\x-0.1-1,2+2*\y) to[bend right] (2*\x-9+0.1,2+2*\y);

%   \end{tikzpicture}
%   \end{center}

%   From there we just have to compute the scalar product of the two vectors with $1\texttt{Mult} + \log_2(q-1)\texttt{Rot} + \log_2(q-1)\texttt{Add}$. \newline

%   So overall we can compute $<$ over $\mathbb{F}_q$ for $q = p^d$ in:

%   \begin{itemize}
%   \item $4\log_2 (q-1) \texttt{Rot}$
%   \item $(4\log_2 (q-1) + 4) \texttt{Add}$
%   \item $(2(\log (p-1) + wt(p-1) + d - 2) + 1) \texttt{Mult}$
%   \item $(\log_2 (q-1) + 1) \texttt{Select}$
%   \end{itemize}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main_pets"
%%% End:
