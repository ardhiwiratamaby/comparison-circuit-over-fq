\subsection{Sorting}
\label{subsec:sorting}

    To demonstrate the efficiency of our comparison algorithms, we applied them to a popular computational task that demands multiple comparisons, sorting.
	The best homomorphic sorting algorithm in terms of running time is the direct sorting algorithm due to {\c C}etin et al.~\cite{CDSS15}.
	For a given array $A = [a_0,\dots,a_{N-1}]$, this algorithm computes a \emph{comparison matrix} $\mL$ defined by
	\begin{align*}
		\mL_{ij} =
		\begin{cases}
			\LT(a_i, a_j) & \text{ if } i < j, \\
			0 & \text{ if } i = j, \\
			1 - \LT(a_j, a_i) & \text{ if } i > j.
		\end{cases}
	\end{align*}
	It is easy to see that the Hamming weight of the $i$th row of $\mL$ is unique and equal to the array index of $a_i$ after sorting the array $A$ in the descending order.
	For example, the zero weight indicates that there are no elements of $A$ bigger than $a_i$. 
	Thus, $a_i$ has a zero index in $A$ after sorting; in other words, $a_i$ is the maximum element of $A$.

	Let $A'$ be a sorted version of $A$ in the descending order.
	To compute $A'[i]$ for any $i \in [0,N-1]$, we homomorphically select an element $a_j$ such that $\wt(\mL[j]) = i$.
	This can be done with the following sum  
	\begin{align}\label{eq:sorting_extraction}
		A'[i] = \sum_{j=0}^{N-1} \EQ_{[0,N-1]}(i,\wt\left(\mL[j]\right)) \cdot a_j\,.
	\end{align}
	Note that the equality function should be defined on the set $[0,N-1]$, which implies that $N$ must be smaller than the plaintext modulus $p$.

	\begin{remark}
		Since the matrix $\mL$ is defined by $N(N-1)/2$ elements, it can be costly to keep it in memory for large~$N$.
		Instead, we can compute the Hamming weights of its rows by iteratively computing one comparison $\LT(a_i, a_j)$ with $i < j$ at a time.
		To achieve this, we create an array of size $N$ initialized with zeros that eventually will store the Hamming weights.
		Then, we add the outcome of $\LT(a_i, a_j)$ to the $i$th element of this array and the result of $1-\LT(a_i, a_j)$ to the $j$th element.
		In this approach, only $N$ elements of the Hamming weight array are being kept in RAM.
	\end{remark}

	The direct sorting algorithm requires $N(N-1)/2$ less-than operations to compute the matrix $\mL$ and $N^2$ equality operations to compute sorted elements of $A'$.
	While computing equalities, we can reduce the total number of non-scalar multiplications if $N$ is large enough.
	Recall $\EQ_\S$ needs $M = \log_2(p-1) + \wt(p-1) - 1$ non-scalar multiplications for any $\S \subseteq [0,p-1]$.
	Hence, to compute $\EQ_{[0,N-1]}(i,\wt\left(\mL[j]\right))$ for all $i \in [0,N-1]$, we should perform $N M$ multiplications.
	%$\EQ(i,\wt\left(\mL[j]\right)) = 1 - (i-\wt\left(\mL[j]\right))^{p-1}$
	Using Lemma~\ref{lem:difference_to_p-1} (see Appendix~\ref{app:proof_thm_less_than_total_degree}), we can rewrite 
	\begin{align*}
		\EQ_{[0,N-1]}\left(i,\wt\left(\mL[j]\right)\right) = 1 - \sum_{k=0}^{p-1} i^k \cdot \wt\left(\mL[j]\right)^{p-1-k}\,.
	\end{align*}
	If we precompute the powers $\wt\left(\mL[j]\right)^{p-1-k}$, then we need only $p-2$ non-scalar multiplications to compute all the equalities $\EQ(i,\wt\left(\mL[j]\right))$ as the index $i$ is not encrypted.
	Hence, if $N > (p-2)/M$, this approach results in a smaller number of non-scalar multiplications.
	Yet, this method introduces $p-1$ scalar multiplications (by powers $i^k$) and $p-2$ additions. 
	However, these operations are much faster in HE schemes than non-scalar multiplication such that the gain from reducing non-scalar multiplications becomes dominant. 
	
	The main advantage of direct sorting is that its multiplicative depth is independent of the array length, namely $d = d\left(\LT\right) + \ceil{\log_2 (p-1)} + 1$.
	This allows to avoid large encryption parameters and costly bootstrapping operations.
	%We can further reduce this depth by computing the Hamming weight modulo a plaintext modulus $p$ that is equal or larger than the length of an array $n$.

\subsection{Minimum and maximum of an array}
\label{sec:min/max}

	Another application of our comparison algorithms is concerned with finding a minimum (or maximum) element of an array.
	To find the minimum of an array with $N$ elements, at least $N-1$ calls of the pairwise minimum function are required~\cite[Chapter 9]{CLR09}, which can be achieved, for instance, by the \emph{tournament method}.
	
	The tournament method consists of $\ceil{\log N}$ iterations.
	In each iteration, the input array is divided into pairs. 
	If the array length is odd, one element is stashed for the next iteration. 
	Then, the maximum of each pair is removed from the array.
	The algorithm stops when only one element is left; this is the minimum of the input array, see Figure~\ref{fig:minimum_tournament}. 
	\begin{figure}
		\centering
		\begin{tikzpicture}
			% first stage
			\draw[black, thin] (0,0) rectangle (1,1);
			\draw[black, thin] (0,1.5) rectangle (1,2.5);
			\draw[black, thin] (0,3.0) rectangle (1,4);
			\draw[black, thin] (0,4.5) rectangle (1,5.5);

			\node at (0.5, 5.0) {$a_0$};
			\node at (0.5, 3.5) {$a_1$};
			\node at (0.5, 2.0) {$a_2$};
			\node at (0.5, 0.5) {$a_3$};

			% second stage
			\draw[black, thin] (1.5,0.75) rectangle (2.5,1.75);
			\draw[black, thin] (1.5,3.75) rectangle (2.5,4.75);

			\node at (2.0, 1.25) {$\min$};
			\node at (2.0, 4.25) {$\min$};

			\draw[black, thin, ->] (1,0.5) -- (2,0.5) -- (2,0.75);
			\draw[black, thin, ->] (1,2) -- (2,2) -- (2,1.75);

			\draw[black, thin, ->] (1,3.5) -- (2,3.5) -- (2,3.75);
			\draw[black, thin, ->] (1,5) -- (2,5) -- (2,4.75);

			% third stage
			\draw[black, thin] (3.0,2.25) rectangle (4.0,3.25);

			\node at (3.5, 2.75) {$\min$};

			\draw[black, thin, ->] (2.5,1.25) -- (3.5,1.25) -- (3.5,2.25);
			\draw[black, thin, ->] (2.5,4.25) -- (3.5,4.25) -- (3.5,3.25);

			% final outcome
			\draw[black, thin, ->] (4.0,2.75) -- (5.0,2.75);
			\node at (6.5, 2.75) {$\min(a_0,a_1,a_2,a_3)$};

		\end{tikzpicture}
		\caption{The tournament method of finding the minimum of an array. In each stage, the array elements are divided into pairs. Only minimum of a pair go to the next stage.}
		\label{fig:minimum_tournament}
	\end{figure}
	Unfortunately, the tournament method has a big multiplicative complexity, namely $\ceil{\log N} \cdot d(\min(x,y))$.
	In the HE world, this enforces us to use either impractical encryption parameters~\cite{TMP15} or a slow bootstrapping function.

	To reduce the depth of the array minimum algorithm, we can combine the tournament method and direct sorting.
	Let $A = [a_0,\dots,a_{N-1}]$ be an input array.
	First, we perform $T$ iterations of the tournament algorithm, which leaves us with an array $A' = [a'_0, \dots, a'_{N'-1}]$ of length $N' = \ceil{N/2^T}$ containing minimal elements of $A$.
	Then, we can find the minimum by computing the comparison table $\mL$ as in direct sorting and extracting one of the minimal elements.
	If $M(f)$ is the non-scalar multiplicative complexity of a function $f$, then the total number of non-scalar multiplications to find the minimum of an array is approximately equal to
	\begin{align*}
		(N - N') \cdot M\left(\min(x,y)\right) + \frac{N'(N'-1)}{2} \cdot M\left(\LT\right) \\
		+ M(\mathtt{Extraction}).
	\end{align*}
	
	The extraction of a minimum element can be done with two methods.
	In the first approach, we use the fact that the Hamming weight of the comparison table row corresponding to the minimum is equal to $N'-1$.
	Hence, we can retrieve the minimum as in~(\ref{eq:sorting_extraction})
	\begin{align}\label{eq:our_minimum}
		\min(A') = \sum_{i=0}^{N'-1} \EQ_{[0,N'-1]}(N'-1,\wt\left(\mL[i]\right)) \cdot a'_i.
	\end{align}
	Here, the multiplicative depth is equal to 
	\begin{align*}
		T \cdot d(\min(x,y)) + d(\LT) + \ceil{\log_2 (p-1)} + 1
	\end{align*}
	which is independent of the input array length $N$.
	Since $\EQ_{[0,N'-1]}$ need $\log_2(p-1) + \wt(p-1) - 1$ non-scalar multiplications, then the number of non-scalar multiplications needed to extract the array minimum is equal to 
	\begin{align*}
		M(\mathtt{Extraction}) = N' (\log_2(p-1) + \wt(p-1) - 1).
	\end{align*}
	Shaul et al.~\cite{PoPETS:SFR20} proposed another circuit to extract the array minimum that exploits the fact that the comparison table row related to the minimum contains only $1$ except for the main diagonal entry.
	In other words, the product of $\prod_{j=1, j \ne i}^{N'} \mL_{ij} = 1$ if and only if $a'_i = \min(A')$.
	Hence, the minimal element is equal to
	\begin{align}\label{eq:shaul_minimum}
		\min(A') = \sum_{i=0}^{N'-1} a'_i \cdot \prod_{j=1, j \ne i}^{N'} \mL_{ij}.
	\end{align}
	The resulting depth of this circuit amounts to
	\begin{align*}
		T \cdot d\left(\min(x,y)\right) + d(\LT) + \ceil{\log (N'-1)} + 1.
	\end{align*}
	This extraction circuit requires the following number of multiplications 
	\begin{align*}
		M(\mathtt{Extraction}) = N' (N'-2).
	\end{align*}
	This implies that for small enough $N'$, Shaul's circuit~(\ref{eq:shaul_minimum}) has a smaller depth or/and a smaller multiplication complexity than the circuit in~(\ref{eq:our_minimum}).
	Furthermore, Shaul's circuit supports any length $N' > p$, whereas (\ref{eq:our_minimum}) requires $N' \le p$ such that $\wt(\mL[i])$ do not overflow modulo $p$.

	In the experiments conducted in Section~\ref{sec:impl-results}, we use the best of these approaches for given $N$, $T$ and $p$. 
	%%%%%%%%%%
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
